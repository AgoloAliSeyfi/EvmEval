{"name":"EvmEval","tagline":"The event mention detection and corefrene evaluators, and associated utilities (converters, validators)","body":"<!-- START doctoc generated TOC please keep comment here to allow auto update -->\r\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\r\n**Table of Contents**\r\n\r\n- [Event Mention Evaluation (EvmEval)](#event-mention-evaluation-evmeval)\r\n  - [Naming Convention](#naming-convention)\r\n  - [Tokenization table files format](#tokenization-table-files-format)\r\n  - [scorer.py](#scorerpy)\r\n    - [*Features*](#features)\r\n    - [*Usage*](#usage)\r\n  - [validator.py](#validatorpy)\r\n    - [*Usage*](#usage-1)\r\n  - [brat2tbf.py](#brat2tbfpy)\r\n    - [*Features*](#features-1)\r\n    - [*Usage*](#usage-2)\r\n  - [LDC-XML-to-Brat converter](#ldc-xml-to-brat-converter)\r\n    - [*Requirements of the software*](#requirements-of-the-software)\r\n    - [*How to run the software*](#how-to-run-the-software)\r\n    - [Assumptions of the software](#assumptions-of-the-software)\r\n  - [Token File Maker](#token-file-maker)\r\n    - [*Prerequisites*](#prerequisites)\r\n    - [*Usage*](#usage-3)\r\n  - [visualize.py](#visualizepy)\r\n    - [*Text Base Visualization*](#text-base-visualization)\r\n    - [*Web Base Visualization*](#web-base-visualization)\r\n    - [*Usage*](#usage-4)\r\n\r\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\r\n\r\n\r\nEvent Mention Evaluation (EvmEval)\r\n=========\r\n\r\nThis repository conducts, file conversion, and scoring for event mention detection. It consists of the following three pieces of code:\r\n 1. A simple converter from Brat annotation tool format to CMU detection format\r\n 2. A scorer that can score system performance based on CMU detection format\r\n 3. A visualizer that use Embedded Brat Viewer\r\n\r\nTo use the software, we need to prepare the CMU format annotation file from the Brat annotation output using \"brat2tbf.py\". The scorer can then take 2 documents in such format, one as gold standard data, one as system output. The scorer also need the token files produced by the tokenizer. The usage of these codes are described below. \r\n\r\nUse the example shell scripts \"example_run.sh\" to perform all the above steps in the sample documents, if success, you will find scoring results in the example_data directory \r\n\r\n\r\nNaming Convention\r\n-------------------\r\nThe following scripts need to find corresponding files by docid and file extension, so the file extension will be provided exactly. The script have default values for these extensions, but may require additional argument if extensions are changed.\r\n\r\nHere is how to find the extension:\r\n\r\nFor tokenization table, they normally have the following name:\r\n\r\n    <docid>.tab\r\n\r\nIn such case, the file extension is \".tab\", both the converter and scorer assume this as a default extension. If not, change them with \"-te\" argument.\r\n\r\nFor brat annotation files, they normally have the following name:\r\n\r\n    <docid>.ann\r\n\r\nIn such case, the file extension is \".ann\", the converter assume this as the default extention. If not, change it with \"-ae\" argument\r\n\r\nTokenization table files format\r\n--------------------------------\r\nThese are tab-delimited files which map the tokens to their tokenized files. A mapping table contains 3 columns for each row, and the rows contain an orderd listing of the\r\ndocument's tokens. The columns are:\r\n  - token_id:   A string of \"t\" followed by a token-number beginning at 0\r\n  - token_str:  The literal string of a given-token\r\n  - tkn_begin:  Index of the token's first character in the tkn file\r\n  - tkn_end:    Index of the token's last character in the tkn file\r\n\r\nPlease note that all 4 fields are required and will be used:\r\n  - The converter will use token_id, tkn_begin, tkn_end to convert characters to token id\r\n  - The scorer will use the token_str to detect invisible words \r\n  \r\nThe tokenization table files are created using our [automatic tool](#token-file-maker), which wraps the Stanford tokenizer and provide boundary checks.\r\n\r\nscorer.py\r\n----------\r\nThe current scorer can score event mention detection and coreference based on the (.tbf) format. It also require the token table files to detect invisible words and to generate\r\nCoNLL style coreference files.\r\n\r\n### *Features*\r\n1. Produce F1-like scoring by mapping system mentions to gold standard mentions,\r\nread the scoring documentation for more details.\r\n2. Be able to produce a comparison output indicating system and gold standard differences:\r\n  a. A text based comparison output (-d option)\r\n  b. A web based comparison output using Brat's embedded visualization (-v option)\r\n3. If specified, it will generate temporary conll format files, and use the conll reference-scorer to produce coreference scores\r\n\r\n### *Usage*\r\n\tusage: scorer_v1.3.py [-h] -g GOLD -s SYSTEM [-d COMPARISON_OUTPUT]\r\n                          [-o OUTPUT] [-c COREF] -t TOKEN_PATH [-of OFFSET_FIELD]\r\n                          [-te TOKEN_TABLE_EXTENSION] [-b]\r\n\r\n\t\r\nEvent mention scorer, which conducts token based scoring, system and gold standard files should follows the token-based format.\r\n\r\n    Required Arguments:\r\n      -g GOLD, --gold GOLD  Golden Standard\r\n      -s SYSTEM, --system SYSTEM\r\n                            System output\r\n      -t TOKEN_PATH, --token_path TOKEN_PATH\r\n                            Path to the directory containing the token mappings\r\n                            file   \r\n    Optional Arguments:\r\n      -h, --help            show this help message and exit                                                    \r\n      -d COMPARISON_OUTPUT, --comparison_output COMPARISON_OUTPUT\r\n                            Compare and help show the difference between system\r\n                            and gold\r\n      -o OUTPUT, --output OUTPUT\r\n                            Optional evaluation result redirects, put eval result\r\n                            to file\r\n      -c COREF, --coref COREF\r\n                            Eval Coreference result output, need to put the\r\n                            referenceconll coref scorer in the same folder with\r\n                            this scorer\r\n      -of OFFSET_FIELD, --offset_field OFFSET_FIELD\r\n                            A pair of integer indicates which column we should\r\n                            read the offset in the token mapping file, index\r\n                            startsat 0, default value will be [2, 3]\r\n      -te TOKEN_TABLE_EXTENSION, --token_table_extension TOKEN_TABLE_EXTENSION\r\n                            any extension appended after docid of token table\r\n                            files. Default is [.txt.tab]\r\n      -b, --debug           turn debug mode on\r\n\r\nvalidator.py\r\n--------------------\r\nThe validator check whether the supplied \"tbf\" file follows assumed structure . \r\n\r\n### *Usage*\r\n    validator.py [-h] -s SYSTEM -t TOKEN_PATH [-of OFFSET_FIELD]\r\n                        [-te TOKEN_TABLE_EXTENSION] [-b]\r\n    \r\n    Event mention scorer, which conducts token based scoring, system and gold\r\n    standard files should follows the token-based format.\r\n    \r\n    optional arguments:\r\n      -h, --help            show this help message and exit\r\n      -s SYSTEM, --system SYSTEM\r\n                            System output\r\n      -t TOKEN_PATH, --token_path TOKEN_PATH\r\n                            Path to the directory containing the token mappings\r\n                            file\r\n      -of OFFSET_FIELD, --offset_field OFFSET_FIELD\r\n                            A pair of integer indicates which column we should\r\n                            read the offset in the token mapping file, index\r\n                            startsat 0, default value will be [2, 3]\r\n      -te TOKEN_TABLE_EXTENSION, --token_table_extension TOKEN_TABLE_EXTENSION\r\n                            any extension appended after docid of token table\r\n                            files. Default is [.txt.tab]\r\n      -b, --debug           turn debug mode on\r\n\r\nbrat2tbf.py\r\n--------------------\r\nThis is a tool that converts Brat Annotation format to TBF format. We currently try to make as little assumption as possible. However, in order to resolve\r\ncoreference transitive redirect automatically, the relation name for coreference must be named as \"Coreference\". We also develop for event coreference only.\r\n\r\n### *Features*\r\n\r\n1. ID convention\r\n\r\nThe default set up follows Brat v1.3 ID convention: \r\n  - T: text-bound annotation\r\n  - R: relation\r\n  - E: event\r\n  - A: attribute\r\n  - M: modification (alias for attribute, for backward compatibility)\r\n  - N: normalization [new in v1.3 of Brat]\r\n  - #: note\r\n\r\nFurther development might allow customized ID convention.\r\n\r\n2. This code only scan and detect event mentions and its attributes. Event arguments and entities are currently not handled. Annotations other than Event Mention (with its attributes and Text Spans) will be ignored, which means, it will only read \"E\" annotations and its related attributes.\r\n\r\n3. Discontinuous text-bound annotations will be supported\r\n\r\n### *Usage*\r\n\r\n\tbrat2tokenFormat.py [-h] (-d DIR | -f FILE) -t TOKENPATH [-o OUT]\r\n                           [-oe EXT] [-i EID] [-w] [-te TOKEN_TABLE_EXTENSION]\r\n                           [-ae ANNOTATION_EXTENSION] [-b]\r\n\r\nThis converter converts Brat annotation files to one single token based event mention description file (CMU format). It accepts a single file name or a directory name that contains the Brat annotation output. The converter also requires token offset files that shares the same name with the annotation file, with extension .txt.tab. The converter will search for the token file in\tthe directory specified by '-t' argument\r\n\r\n\tRequired Arguments:\r\n\t  -d DIR, --dir DIR     directory of the annotation files\r\n\t  -f FILE, --file FILE  name of one annotation file\r\n\t  -t TOKENPATH, --tokenPath TOKENPATH\r\n                        directory to search for the corresponding token files\r\n\r\n\tOptional arguments:\r\n\t  -h, --help            show this help message and exit\r\n\t  -o OUT, --out OUT     output path, 'converted' in the current path by\r\n\t\t\t\t\t\t\tdefault\r\n\t  -oe EXT, --ext EXT    output extension, 'tbf' by default\r\n\t  -i EID, --eid EID     an engine id that will appears at each line of the\r\n\t\t\t\t\t\t\toutput file. 'brat_conversion' will be used by default\r\n\t  -w, --overwrite       force overwrite existing output file\r\n\t  -te TOKEN_TABLE_EXTENSION, --token_table_extension TOKEN_TABLE_EXTENSION\r\n\t\t\t\t\t\t\tany extension appended after docid of token table\r\n\t\t\t\t\t\t\tfiles. Default is .txt.tab\r\n\t  -ae ANNOTATION_EXTENSION, --annotation_extension ANNOTATION_EXTENSION\r\n\t\t\t\t\t\t\tany extension appended after docid of annotation\r\n\t\t\t\t\t\t\tfiles. Default is .tkn.ann\r\n\t  -b, --debug           turn debug mode on\r\n \r\nLDC-XML-to-Brat converter\r\n------------\r\nThis software converts LDC's XML format for the [TAC KBP 2015 Event Nugget task](http://cairo.lti.cs.cmu.edu/kbp/2015/event/) to the [Brat format](http://brat.nlplab.org/standoff.html).  More specifically, it converts LDC's event nuggets and coreferences to events and coreference links that can be viewed via the Brat web interface.  Brat annotation configurations for output are available at directory `src/main/resources/`.\r\nThe software is located at the direcotry: ldc-xml-to-brat-converter, you can built it from source using Maven.  You can also find a pre-compiled version in the bin/g directory\r\n\r\n### *Requirements of the software*\r\nThe software requires Java 1.8 and [Annobase](http://junaraki.net/software/annobase) 1.0.1.  See `pom.xml` for other dependencies.\r\n\r\n### *How to run the software*\r\nYou can see its usage with the following command:\r\n```\r\n$ java LdcXmlToBratConverter\r\nOption           Description     \r\n------           -----------     \r\n-h               help            \r\n-i <input dir>   input directory \r\n-o <output dir>  output directory\r\n```\r\n\r\n### Assumptions of the software\r\nThe software assumes that the following two types of input files are given with the fixed file extensions.\r\n- text file (with tags): *.mpdf.xml\r\n- annotation file: *.rich_ere.xml\r\n \r\n \r\nToken File Maker\r\n------------\r\n### *Prerequisites*\r\nOur tokenizer implementation is based on the tokenizer in the Stanford CoreNLP tool .  The software is implemented in Java, and its requirements are as follows:\r\n 1.\tJava 1.8\r\n 2.\tThe same number of text files and brat annotation files (*.ann) with the same file base name\r\n\r\n### *Usage*\r\n\r\n    java -jar bin/token-file-maker-1.0.3-jar-with-dependencies.jar -a <annotation> -e <extension> [-h] -o <output> [-s <separator>] -t <text>\r\n        -a <annotation>   annotation directory\r\n        -e <extension>    text file extension\r\n        -h                print this message\r\n        -o <output>       output directory\r\n        -s <separator>    separator chars for tokenization\r\n        -t <text>         text directory\r\n\r\n \r\nvisualize.py\r\n------------\r\n\r\nThe visualization is provided as a mechanism to compare different output, which is optional and can be ignored if one is only interested in the scores. This code maybe update frequently. Please refer to the command line \"-h\" for detailed instructions.\r\n\r\nThe visualize code represent mention differences in JSON, which is then passed to [Embedded Brat](http://brat.nlplab.org/embed.html) .  \r\n\r\nRecent changes make visualizing clusters possible by creating additional JSON object. When enabled, there will be a cluster selector on the webpage, one could select the cluster and all other event mentions will hide.\r\n\r\n### *Text Base Visualization*\r\nThe text based Visualization can be generated using the \"scorer.py\", by supplying the \"-d\"\r\nargument. The format is straightforward, a text document is produced for comparison.\r\nThe annotation of both systems are displayed in one line, separated by \"|\"\r\n\r\n### *Web Base Visualization*\r\nThe web base visualization takes the text visualization file, then: \r\n  1. convert them to Brat Embedded JSON format and store it at the visualization \r\n  folder (visualization/json)\r\n  2. It will start a server at the visualization folder using localhost:8000\r\n  3. Now user can browse the locally hosted site for comparison\r\n  4. User can stop the server when done, and restart it at anytime using \"start.sh\", it is \r\n  no longer necessary to regenerate the JSON data if one only wish to use the old ones\r\n  \r\n\r\n### *Usage*\r\n    usage: visualize.py [-h] -d COMPARISON_OUTPUT -t TOKENPATH [-x TEXT]\r\n                    [-v VISUALIZATION_HTML_PATH] [-of OFFSET_FIELD]\r\n                    [-te TOKEN_TABLE_EXTENSION] [-se SOURCE_FILE_EXTENSION]\r\n\r\nMention visualizer, will create a side-by-side embedded visualization from the\r\nmapping\r\n\r\n    Required Arguments:\r\n      -d COMPARISON_OUTPUT, --comparison_output COMPARISON_OUTPUT\r\n                            The comparison output file between system and gold,\r\n                            used to recover the mapping\r\n      -t TOKENPATH, --tokenPath TOKENPATH\r\n                            Path to the directory containing the token mappings\r\n                            file\r\n    Optional Arguments:\r\n      -h, --help            show this help message and exit                    \r\n      -x TEXT, --text TEXT  Path to the directory containing the original text\r\n      -v VISUALIZATION_HTML_PATH, --visualization_html_path VISUALIZATION_HTML_PATH\r\n                            The Path to find visualization web pages, default path\r\n                            is [visualization]\r\n      -of OFFSET_FIELD, --offset_field OFFSET_FIELD\r\n                            A pair of integer indicates which column we should\r\n                            read the offset in the token mapping file, index\r\n                            startsat 0, default value will be [2, 3]\r\n      -te TOKEN_TABLE_EXTENSION, --token_table_extension TOKEN_TABLE_EXTENSION\r\n                            any extension appended after docid of token table\r\n                            files. Default is [.txt.tab]\r\n      -se SOURCE_FILE_EXTENSION, --source_file_extension SOURCE_FILE_EXTENSION\r\n                            any extension appended after docid of source\r\n                            files.Default is [.tkn.txt]\r\n","google":"UA-62709601-1","note":"Don't delete this file! It's used internally to help with page regeneration."}